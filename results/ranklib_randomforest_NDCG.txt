
[+] General Parameters:
LETOR 4.0 dataset: No
Training data:	../data/MQ2008/Fold1/train.txt
Test data:	../data/MQ2008/Fold1/test.txt
Validation data:	../data/MQ2008/Fold1/vali.txt
Ranking method:	Random Forests
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	ERR@10
Highest relevance label (to compute ERR): 4
Feature normalization: No
Model file: ../results/ranklib_randomforest_model

[+] Random Forests's Parameters:
No. of bags: 300
Sub-sampling: 1.0
Feature-sampling: 0.3
No. of trees: 1
No. of leaves: 100
No. of threshold candidates: 256
Learning rate: 0.1

Reading feature file [../data/MQ2008/Fold1/train.txt]: 0... Reading feature file [../data/MQ2008/Fold1/train.txt]... [Done.]
(471 ranked lists, 9630 entries read)
Reading feature file [../data/MQ2008/Fold1/vali.txt]: 0... Reading feature file [../data/MQ2008/Fold1/vali.txt]... [Done.]
(157 ranked lists, 2707 entries read)
Reading feature file [../data/MQ2008/Fold1/test.txt]: 0... Reading feature file [../data/MQ2008/Fold1/test.txt]... [Done.]
(156 ranked lists, 2874 entries read)
Initializing... [Done]
------------------------------------
Training starts...
------------------------------------
bag       | NDCG@10-B | NDCG@10-OOB |
------------------------------------
b[1]      | 0.5604    |
b[2]      | 0.5249    |
b[3]      | 0.56      |
b[4]      | 0.5946    |
b[5]      | 0.5803    |
b[6]      | 0.5618    |
b[7]      | 0.5528    |
b[8]      | 0.5164    |
b[9]      | 0.5504    |
b[10]     | 0.5445    |
b[11]     | 0.563     |
b[12]     | 0.5513    |
b[13]     | 0.542     |
b[14]     | 0.52      |
b[15]     | 0.5803    |
b[16]     | 0.5743    |
b[17]     | 0.5358    |
b[18]     | 0.5782    |
b[19]     | 0.5589    |
b[20]     | 0.5165    |
b[21]     | 0.5611    |
b[22]     | 0.6104    |
b[23]     | 0.5494    |
b[24]     | 0.5374    |
b[25]     | 0.5964    |
b[26]     | 0.5693    |
b[27]     | 0.5719    |
b[28]     | 0.5488    |
b[29]     | 0.5664    |
b[30]     | 0.5692    |
b[31]     | 0.5325    |
b[32]     | 0.5363    |
b[33]     | 0.5863    |
b[34]     | 0.5479    |
b[35]     | 0.5016    |
b[36]     | 0.5387    |
b[37]     | 0.5779    |
b[38]     | 0.5401    |
b[39]     | 0.5509    |
b[40]     | 0.5893    |
b[41]     | 0.5794    |
b[42]     | 0.5379    |
b[43]     | 0.5657    |
b[44]     | 0.5318    |
b[45]     | 0.53      |
b[46]     | 0.5536    |
b[47]     | 0.5432    |
b[48]     | 0.5637    |
b[49]     | 0.5619    |
b[50]     | 0.5473    |
b[51]     | 0.5429    |
b[52]     | 0.5869    |
b[53]     | 0.5456    |
b[54]     | 0.5608    |
b[55]     | 0.5626    |
b[56]     | 0.5451    |
b[57]     | 0.5369    |
b[58]     | 0.5517    |
b[59]     | 0.5753    |
b[60]     | 0.5575    |
b[61]     | 0.5455    |
b[62]     | 0.556     |
b[63]     | 0.5588    |
b[64]     | 0.5554    |
b[65]     | 0.5263    |
b[66]     | 0.5476    |
b[67]     | 0.5217    |
b[68]     | 0.5511    |
b[69]     | 0.5474    |
b[70]     | 0.561     |
b[71]     | 0.5621    |
b[72]     | 0.5526    |
b[73]     | 0.5525    |
b[74]     | 0.5618    |
b[75]     | 0.5334    |
b[76]     | 0.5718    |
b[77]     | 0.5465    |
b[78]     | 0.5523    |
b[79]     | 0.584     |
b[80]     | 0.5726    |
b[81]     | 0.5409    |
b[82]     | 0.5592    |
b[83]     | 0.5464    |
b[84]     | 0.5504    |
b[85]     | 0.5616    |
b[86]     | 0.532     |
b[87]     | 0.5465    |
b[88]     | 0.5519    |
b[89]     | 0.5435    |
b[90]     | 0.5782    |
b[91]     | 0.5484    |
b[92]     | 0.553     |
b[93]     | 0.5639    |
b[94]     | 0.5435    |
b[95]     | 0.5698    |
b[96]     | 0.5542    |
b[97]     | 0.531     |
b[98]     | 0.5568    |
b[99]     | 0.5571    |
b[100]    | 0.5539    |
b[101]    | 0.547     |
b[102]    | 0.5791    |
b[103]    | 0.5564    |
b[104]    | 0.5849    |
b[105]    | 0.5697    |
b[106]    | 0.5354    |
b[107]    | 0.5542    |
b[108]    | 0.5188    |
b[109]    | 0.5785    |
b[110]    | 0.5673    |
b[111]    | 0.5591    |
b[112]    | 0.5808    |
b[113]    | 0.5401    |
b[114]    | 0.5383    |
b[115]    | 0.524     |
b[116]    | 0.5374    |
b[117]    | 0.5469    |
b[118]    | 0.5523    |
b[119]    | 0.5172    |
b[120]    | 0.5535    |
b[121]    | 0.561     |
b[122]    | 0.546     |
b[123]    | 0.593     |
b[124]    | 0.5454    |
b[125]    | 0.5624    |
b[126]    | 0.5292    |
b[127]    | 0.5093    |
b[128]    | 0.6011    |
b[129]    | 0.5457    |
b[130]    | 0.5537    |
b[131]    | 0.5692    |
b[132]    | 0.5648    |
b[133]    | 0.5836    |
b[134]    | 0.5645    |
b[135]    | 0.5419    |
b[136]    | 0.5532    |
b[137]    | 0.5516    |
b[138]    | 0.5384    |
b[139]    | 0.5411    |
b[140]    | 0.5493    |
b[141]    | 0.5946    |
b[142]    | 0.5272    |
b[143]    | 0.5713    |
b[144]    | 0.545     |
b[145]    | 0.5553    |
b[146]    | 0.5342    |
b[147]    | 0.5447    |
b[148]    | 0.5688    |
b[149]    | 0.5695    |
b[150]    | 0.5384    |
b[151]    | 0.5521    |
b[152]    | 0.5776    |
b[153]    | 0.5325    |
b[154]    | 0.5744    |
b[155]    | 0.5396    |
b[156]    | 0.5934    |
b[157]    | 0.5439    |
b[158]    | 0.5562    |
b[159]    | 0.544     |
b[160]    | 0.5514    |
b[161]    | 0.5591    |
b[162]    | 0.5826    |
b[163]    | 0.5514    |
b[164]    | 0.5316    |
b[165]    | 0.5619    |
b[166]    | 0.5568    |
b[167]    | 0.5281    |
b[168]    | 0.5667    |
b[169]    | 0.5338    |
b[170]    | 0.5766    |
b[171]    | 0.603     |
b[172]    | 0.5901    |
b[173]    | 0.5742    |
b[174]    | 0.5767    |
b[175]    | 0.5619    |
b[176]    | 0.5504    |
b[177]    | 0.5656    |
b[178]    | 0.6002    |
b[179]    | 0.5573    |
b[180]    | 0.5411    |
b[181]    | 0.5614    |
b[182]    | 0.5678    |
b[183]    | 0.5434    |
b[184]    | 0.5308    |
b[185]    | 0.5776    |
b[186]    | 0.5246    |
b[187]    | 0.561     |
b[188]    | 0.5443    |
b[189]    | 0.6012    |
b[190]    | 0.569     |
b[191]    | 0.577     |
b[192]    | 0.5716    |
b[193]    | 0.5907    |
b[194]    | 0.5479    |
b[195]    | 0.5643    |
b[196]    | 0.5484    |
b[197]    | 0.5595    |
b[198]    | 0.5584    |
b[199]    | 0.585     |
b[200]    | 0.5674    |
b[201]    | 0.5602    |
b[202]    | 0.5479    |
b[203]    | 0.5323    |
b[204]    | 0.5783    |
b[205]    | 0.5504    |
b[206]    | 0.5128    |
b[207]    | 0.5764    |
b[208]    | 0.5678    |
b[209]    | 0.5638    |
b[210]    | 0.5395    |
b[211]    | 0.5304    |
b[212]    | 0.5396    |
b[213]    | 0.5576    |
b[214]    | 0.5518    |
b[215]    | 0.5622    |
b[216]    | 0.5823    |
b[217]    | 0.5736    |
b[218]    | 0.5652    |
b[219]    | 0.5248    |
b[220]    | 0.5518    |
b[221]    | 0.5674    |
b[222]    | 0.5224    |
b[223]    | 0.538     |
b[224]    | 0.5252    |
b[225]    | 0.5435    |
b[226]    | 0.5747    |
b[227]    | 0.5691    |
b[228]    | 0.5581    |
b[229]    | 0.5381    |
b[230]    | 0.5379    |
b[231]    | 0.5793    |
b[232]    | 0.5728    |
b[233]    | 0.5767    |
b[234]    | 0.5473    |
b[235]    | 0.5431    |
b[236]    | 0.5703    |
b[237]    | 0.5629    |
b[238]    | 0.5817    |
b[239]    | 0.5691    |
b[240]    | 0.5581    |
b[241]    | 0.5739    |
b[242]    | 0.5596    |
b[243]    | 0.5675    |
b[244]    | 0.549     |
b[245]    | 0.5355    |
b[246]    | 0.5691    |
b[247]    | 0.5841    |
b[248]    | 0.5507    |
b[249]    | 0.5386    |
b[250]    | 0.5562    |
b[251]    | 0.5663    |
b[252]    | 0.5727    |
b[253]    | 0.5548    |
b[254]    | 0.5859    |
b[255]    | 0.6222    |
b[256]    | 0.5467    |
b[257]    | 0.5696    |
b[258]    | 0.5762    |
b[259]    | 0.5839    |
b[260]    | 0.5358    |
b[261]    | 0.5527    |
b[262]    | 0.5803    |
b[263]    | 0.5631    |
b[264]    | 0.5756    |
b[265]    | 0.519     |
b[266]    | 0.5727    |
b[267]    | 0.5403    |
b[268]    | 0.5582    |
b[269]    | 0.5166    |
b[270]    | 0.5755    |
b[271]    | 0.5739    |
b[272]    | 0.5476    |
b[273]    | 0.5616    |
b[274]    | 0.5239    |
b[275]    | 0.5338    |
b[276]    | 0.5805    |
b[277]    | 0.5472    |
b[278]    | 0.5275    |
b[279]    | 0.5666    |
b[280]    | 0.5361    |
b[281]    | 0.5751    |
b[282]    | 0.5493    |
b[283]    | 0.5458    |
b[284]    | 0.5582    |
b[285]    | 0.5253    |
b[286]    | 0.5432    |
b[287]    | 0.5364    |
b[288]    | 0.5664    |
b[289]    | 0.5518    |
b[290]    | 0.5898    |
b[291]    | 0.5764    |
b[292]    | 0.5626    |
b[293]    | 0.5741    |
b[294]    | 0.5442    |
b[295]    | 0.5711    |
b[296]    | 0.5502    |
b[297]    | 0.5555    |
b[298]    | 0.5451    |
b[299]    | 0.5432    |
b[300]    | 0.556     |
------------------------------------
Finished sucessfully.
NDCG@10 on training data: 0.5854
NDCG@10 on validation data: 0.544
------------------------------------
ERR@10 on test data: 0.0966

Model saved to: ../results/ranklib_randomforest_model
