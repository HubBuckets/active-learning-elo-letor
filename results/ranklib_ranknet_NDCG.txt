
[+] General Parameters:
LETOR 4.0 dataset: No
Training data:	../data/MQ2008/Fold1/train.txt
Test data:	../data/MQ2008/Fold1/test.txt
Validation data:	../data/MQ2008/Fold1/vali.txt
Ranking method:	RankNet
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	ERR@10
Highest relevance label (to compute ERR): 4
Feature normalization: No
Model file: ../results/ranklib_ranknet_model

[+] RankNet's Parameters:
No. of epochs: 100
No. of hidden layers: 1
No. of hidden nodes per layer: 10
Learning rate: 5.0E-5

Reading feature file [../data/MQ2008/Fold1/train.txt]: 0... Reading feature file [../data/MQ2008/Fold1/train.txt]... [Done.]
(471 ranked lists, 9630 entries read)
Reading feature file [../data/MQ2008/Fold1/vali.txt]: 0... Reading feature file [../data/MQ2008/Fold1/vali.txt]... [Done.]
(157 ranked lists, 2707 entries read)
Reading feature file [../data/MQ2008/Fold1/test.txt]: 0... Reading feature file [../data/MQ2008/Fold1/test.txt]... [Done.]
(156 ranked lists, 2874 entries read)
Initializing... [Done]
-----------------------------------------
Training starts...
--------------------------------------------------
#epoch  | % mis-ordered  | NDCG@10-T | NDCG@10-V |
        |   pairs        |           |           |
--------------------------------------------------
1       | 0.174          | 0.4127    | 0.4832    |
2       | 0.1652         | 0.4212    | 0.4924    |
3       | 0.158          | 0.4301    | 0.4946    |
4       | 0.1519         | 0.4376    | 0.5028    |
5       | 0.1465         | 0.4441    | 0.5056    |
6       | 0.1425         | 0.4496    | 0.5046    |
7       | 0.1381         | 0.4543    | 0.51      |
8       | 0.1351         | 0.4603    | 0.5109    |
9       | 0.1322         | 0.4641    | 0.5097    |
10      | 0.1298         | 0.4672    | 0.5122    |
11      | 0.1274         | 0.4729    | 0.513     |
12      | 0.1255         | 0.4738    | 0.5157    |
13      | 0.1248         | 0.4747    | 0.5167    |
14      | 0.1234         | 0.4765    | 0.519     |
15      | 0.1229         | 0.4772    | 0.5219    |
16      | 0.1218         | 0.4789    | 0.5207    |
17      | 0.1204         | 0.4813    | 0.5217    |
18      | 0.1196         | 0.4822    | 0.5229    |
19      | 0.1183         | 0.4837    | 0.5246    |
20      | 0.1175         | 0.4852    | 0.5243    |
21      | 0.1166         | 0.485     | 0.5236    |
22      | 0.116          | 0.4861    | 0.5289    |
23      | 0.1154         | 0.4866    | 0.5268    |
24      | 0.1146         | 0.4874    | 0.5257    |
25      | 0.1142         | 0.487     | 0.5263    |
26      | 0.1136         | 0.4865    | 0.5279    |
27      | 0.1128         | 0.4867    | 0.5278    |
28      | 0.1124         | 0.4862    | 0.5259    |
29      | 0.1117         | 0.4874    | 0.5249    |
30      | 0.1113         | 0.4872    | 0.5249    |
31      | 0.111          | 0.487     | 0.5254    |
32      | 0.1107         | 0.4869    | 0.5255    |
33      | 0.1105         | 0.4865    | 0.5254    |
34      | 0.1104         | 0.4877    | 0.5232    |
35      | 0.1103         | 0.4867    | 0.5235    |
36      | 0.1099         | 0.4867    | 0.5238    |
37      | 0.11           | 0.4867    | 0.524     |
38      | 0.1097         | 0.4877    | 0.5242    |
39      | 0.1093         | 0.4883    | 0.5214    |
40      | 0.109          | 0.488     | 0.5215    |
41      | 0.1088         | 0.488     | 0.5204    |
42      | 0.1087         | 0.4877    | 0.5207    |
43      | 0.1085         | 0.4877    | 0.5178    |
44      | 0.1085         | 0.4887    | 0.5165    |
45      | 0.1085         | 0.4886    | 0.5164    |
46      | 0.1085         | 0.4878    | 0.5188    |
47      | 0.1084         | 0.4876    | 0.5185    |
48      | 0.1083         | 0.4877    | 0.519     |
49      | 0.1083         | 0.4884    | 0.5187    |
50      | 0.1084         | 0.4879    | 0.5173    |
51      | 0.1083         | 0.4882    | 0.5173    |
52      | 0.1081         | 0.488     | 0.5173    |
53      | 0.1082         | 0.4878    | 0.5169    |
54      | 0.1082         | 0.4877    | 0.5177    |
55      | 0.1082         | 0.4875    | 0.5177    |
56      | 0.1082         | 0.4873    | 0.5173    |
57      | 0.1081         | 0.4872    | 0.5173    |
58      | 0.1081         | 0.4865    | 0.5168    |
59      | 0.1079         | 0.4872    | 0.5169    |
60      | 0.1078         | 0.4877    | 0.5166    |
61      | 0.1077         | 0.4882    | 0.5166    |
62      | 0.1077         | 0.4881    | 0.5174    |
63      | 0.1076         | 0.4884    | 0.5185    |
64      | 0.1076         | 0.4884    | 0.5186    |
65      | 0.1076         | 0.4882    | 0.5192    |
66      | 0.1076         | 0.4882    | 0.5191    |
67      | 0.1077         | 0.4881    | 0.5191    |
68      | 0.1076         | 0.488     | 0.519     |
69      | 0.1076         | 0.4879    | 0.5193    |
70      | 0.1075         | 0.4883    | 0.5217    |
71      | 0.1074         | 0.4884    | 0.5208    |
72      | 0.1075         | 0.4886    | 0.5208    |
73      | 0.1074         | 0.4879    | 0.5208    |
74      | 0.1075         | 0.4875    | 0.5208    |
75      | 0.1075         | 0.4874    | 0.5205    |
76      | 0.1074         | 0.4874    | 0.5201    |
77      | 0.1074         | 0.4874    | 0.5205    |
78      | 0.1073         | 0.4871    | 0.5205    |
79      | 0.1073         | 0.4868    | 0.5207    |
80      | 0.1074         | 0.4862    | 0.5207    |
81      | 0.1074         | 0.4861    | 0.5206    |
82      | 0.1073         | 0.486     | 0.5205    |
83      | 0.1073         | 0.4857    | 0.5197    |
84      | 0.1073         | 0.4857    | 0.5205    |
85      | 0.1072         | 0.4859    | 0.5205    |
86      | 0.1072         | 0.4858    | 0.5182    |
87      | 0.1072         | 0.4856    | 0.5177    |
88      | 0.1071         | 0.4859    | 0.5177    |
89      | 0.1071         | 0.4856    | 0.5173    |
90      | 0.1071         | 0.4858    | 0.5173    |
91      | 0.1071         | 0.4856    | 0.5172    |
92      | 0.107          | 0.4856    | 0.5171    |
93      | 0.107          | 0.4854    | 0.5171    |
94      | 0.1071         | 0.485     | 0.5183    |
95      | 0.107          | 0.485     | 0.5179    |
96      | 0.1071         | 0.485     | 0.5179    |
97      | 0.107          | 0.4854    | 0.5177    |
98      | 0.1071         | 0.4853    | 0.5175    |
99      | 0.1071         | 0.4851    | 0.5175    |
100     | 0.1072         | 0.4853    | 0.5175    |
--------------------------------------------------
Finished sucessfully.
NDCG@10 on training data: 0.4861
NDCG@10 on validation data: 0.5289
---------------------------------
ERR@10 on test data: 0.0919

Model saved to: ../results/ranklib_ranknet_model
